{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671d3c56",
   "metadata": {},
   "source": [
    "# NBA Data: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a9913",
   "metadata": {},
   "source": [
    "Knowing the amount of number of 2-point shots, 3-point shots, and free-throws, should theoretically predict the winner of a basketball game with 100% accuracy because the team that scores the most points wins and those are all 3 ways to score points. I could throw all of my dependent variables in the model and have something incredibly accurate but that doesn't help teams strategize in this hypothetical scenario because that would essentily say \"The team that wins in every possible stat category will win the game\" which is obvious.\n",
    "\n",
    "The value of this model is to provide guidance in team building and training. No team is ever \\#1 in every stat category. That's not feasable. Instead I'm going to limit the model to only 3 inputs. This way, a caoch and go to their team and say \"This year, we will focus on 3 things\". Keep it simple for the team so they don't get scatterbrained trying to do too much. \n",
    "\n",
    "First, I will build the model to predict winning using all inputs. Then I will look at the feature importance to extract the 3 most useful features to predict winning. Finally, I will rebuild the model using only those 3 features. I will repeat this process for two to three different models to find the best combination of model and features to predict winning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be36a66c",
   "metadata": {},
   "source": [
    "Model\n",
    "Explanation\n",
    "All features\n",
    "use just best parameters (3\n",
    "rebuild with 3\n",
    "cross validation somewhere on training set\n",
    "test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db5c5bb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "249cf236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad596ac",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a6e1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_df = pickle.load(open(\"data_clean/nba_df3.pkl\", \"rb\"))\n",
    "X_train_scaled = pickle.load(open(\"data_clean/X_train_scaled.pkl\", \"rb\"))\n",
    "X_test_scaled = pickle.load(open(\"data_clean/X_test_scaled.pkl\", \"rb\"))\n",
    "y_train = pickle.load(open(\"data_clean/y_train.pkl\", \"rb\"))\n",
    "y_test = pickle.load(open(\"data_clean/y_test.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ffc9b9",
   "metadata": {},
   "source": [
    "## Circling Back\n",
    "\n",
    "After running a few tests I realized that including a metric for field goals which is just the summation of 2-point and 3-point field goals is reudnant. So I'm going to remove the fga and fg_pct inputs while keeping the more detailed 2-point and 3-point related inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f832326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fg2a</th>\n",
       "      <th>fg2_pct</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fta</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>reb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>to</th>\n",
       "      <th>pf</th>\n",
       "      <th>win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.0</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>41.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>48.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.0</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51332</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>55.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51333</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51334</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>52.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51335</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51336</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51328 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fg2a   fg2_pct  fg3a   fg3_pct   fta    ft_pct   reb   ast   stl  blk  \\\n",
       "0      68.0  0.470588   8.0  0.250000  30.0  0.500000  38.0  20.0   9.0  4.0   \n",
       "1      63.0  0.492063   7.0  0.142857  34.0  0.735294  41.0  23.0   8.0  4.0   \n",
       "2      66.0  0.545455  15.0  0.266667  34.0  0.617647  48.0  25.0  18.0  7.0   \n",
       "3      62.0  0.483871  13.0  0.153846  40.0  0.700000  43.0  20.0   9.0  4.0   \n",
       "4      71.0  0.478873   6.0  0.666667  29.0  0.689655  52.0  25.0  10.0  7.0   \n",
       "...     ...       ...   ...       ...   ...       ...   ...   ...   ...  ...   \n",
       "51332  75.0  0.346667  22.0  0.363636  24.0  0.833333  55.0  20.0   5.0  7.0   \n",
       "51333  59.0  0.440678  41.0  0.365854  21.0  0.857143  40.0  30.0   9.0  4.0   \n",
       "51334  65.0  0.615385  28.0  0.500000  26.0  0.769231  52.0  34.0   7.0  9.0   \n",
       "51335  60.0  0.500000  34.0  0.352941  20.0  0.800000  48.0  30.0   7.0  7.0   \n",
       "51336  63.0  0.396825  35.0  0.428571  26.0  0.846154  47.0  22.0  14.0  6.0   \n",
       "\n",
       "         to    pf   win  \n",
       "0      18.0  34.0  loss  \n",
       "1      18.0  26.0   win  \n",
       "2      25.0  35.0   win  \n",
       "3      24.0  26.0  loss  \n",
       "4      25.0  33.0   win  \n",
       "...     ...   ...   ...  \n",
       "51332   8.0  22.0  loss  \n",
       "51333  14.0  19.0  loss  \n",
       "51334  15.0  20.0   win  \n",
       "51335  21.0  23.0  loss  \n",
       "51336  13.0  23.0   win  \n",
       "\n",
       "[51328 rows x 13 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_df = nba_df.drop(columns = [\"fga\", \"fg_pct\"])\n",
    "X_train_scaled = X_train_scaled.drop(columns = [\"fga\", \"fg_pct\"])\n",
    "X_test_scaled = X_test_scaled.drop(columns = [\"fga\", \"fg_pct\"])\n",
    "nba_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfb4aee",
   "metadata": {},
   "source": [
    "## Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a204ba14",
   "metadata": {},
   "source": [
    "The first model I will try is Logistic Regression. My output variable is win vs loss so I have to stick with categorical models and with this output variable being dichotomous, it makes sense to try Logistic Regression first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41e9151",
   "metadata": {},
   "source": [
    "### Get top 3 Features\n",
    "\n",
    "First I will build a model with all features, create an ordered list of the features by their importance, then I will extract the top 3. Those 3 features will be used to build the real model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2813ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reb        2.146340\n",
       "fg3a       1.863932\n",
       "fg2a       1.490386\n",
       "fg2_pct    1.306337\n",
       "to         1.201043\n",
       "fg3_pct    1.197691\n",
       "stl        1.032633\n",
       "ft_pct     0.442312\n",
       "ast        0.437753\n",
       "blk        0.281330\n",
       "fta        0.252609\n",
       "pf         0.218038\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/34052115/how-to-find-the-importance-of-the-features-for-a-logistic-regression-model\n",
    "# https://stackoverflow.com/questions/24255723/sklearn-logistic-regression-important-features\n",
    "# This is already scaled so I dont need the std. its already 1\n",
    "\n",
    "log_reg_all = LogisticRegression(solver = 'liblinear', max_iter = 500, C = 1000)\n",
    "log_reg_all.fit(X_train_scaled, y_train)\n",
    "log_reg_feature_list = np.abs(np.std(X_train_scaled) * log_reg_all.coef_[0]).sort_values(ascending = False) \n",
    "\n",
    "log_reg_top_features = list(log_reg_feature_list[0:3].index)\n",
    "log_reg_feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605f4478",
   "metadata": {},
   "source": [
    "The top 3 features are are reb (rebounds), fg3a (3-pointers attempted), and fg2a (2-pointers attempted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf7933",
   "metadata": {},
   "source": [
    "### Rebuild Model using Top 3 Features\n",
    "\n",
    "Now I will rebuild the model only using the top 3 feaures found in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6646242",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_log_reg_top3 = X_train_scaled[log_reg_top_features]\n",
    "X_test_scaled_log_reg_top3 = X_test_scaled[log_reg_top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf0135e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, max_iter=500, solver='liblinear')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_top3 = LogisticRegression(solver = 'liblinear', max_iter = 500, C = 1000)\n",
    "log_reg_top3.fit(X_train_scaled_log_reg_top3, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98591b19",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "974a8362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Mean Score: 0.6329 (Std: 0.0068)\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       0.63      0.64      0.63      7693\n",
      "         win       0.63      0.63      0.63      7706\n",
      "\n",
      "    accuracy                           0.63     15399\n",
      "   macro avg       0.63      0.63      0.63     15399\n",
      "weighted avg       0.63      0.63      0.63     15399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits = 10, random_state = 610, shuffle = True)\n",
    "scores = cross_val_score(log_reg_top3, X_train_scaled_log_reg_top3, y_train, cv = cv)\n",
    "print(\"Cross Validation Mean Score: \", round(np.mean(scores), 4), \" (Std: \", round(np.std(scores), 4), \")\", sep = \"\")\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, log_reg_top3.predict(X_test_scaled_log_reg_top3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e30d6353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features</th>\n",
       "      <th>train_cv_mean</th>\n",
       "      <th>train_cv_std</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_win</th>\n",
       "      <th>precision_loss</th>\n",
       "      <th>recall_win</th>\n",
       "      <th>recall_loss</th>\n",
       "      <th>f1_win</th>\n",
       "      <th>f1_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[reb, fg3a, fg2a]</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.6328</td>\n",
       "      <td>0.6287</td>\n",
       "      <td>0.6368</td>\n",
       "      <td>0.6342</td>\n",
       "      <td>0.6313</td>\n",
       "      <td>0.6315</td>\n",
       "      <td>0.6341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model              features       train_cv_mean  train_cv_std    \\\n",
       "0  Logistic Regression  [reb, fg3a, fg2a]         0.6329         0.0068   \n",
       "\n",
       "  accuracy       precision_win  precision_loss recall_win     recall_loss     \\\n",
       "0         0.6328         0.6287         0.6368         0.6342         0.6313   \n",
       "\n",
       "  f1_win         f1_loss         \n",
       "0         0.6315         0.6341  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics = pd.array([\"model\", \"features\", \"train_cv_mean\", \"train_cv_std\", \"accuracy\", \"precision_win\", \"precision_loss\", \"recall_win\", \"recall_loss\", \"f1_win\", \"f1_loss\"])\n",
    "\n",
    "log_reg_evaluation = pd.array([\"Logistic Regression\", \n",
    "                               log_reg_top_features,\n",
    "                               round(np.mean(scores), 4), \n",
    "                               round(np.std(scores), 4), \n",
    "                               round(accuracy_score(log_reg_top3.predict(X_test_scaled_log_reg_top3), y_test), 4), \n",
    "                               round(precision_score(log_reg_top3.predict(X_test_scaled_log_reg_top3), y_test, pos_label = 'win'), 4), \n",
    "                               round(precision_score(log_reg_top3.predict(X_test_scaled_log_reg_top3), y_test, pos_label = 'loss'), 4), \n",
    "                               round(recall_score(log_reg_top3.predict(X_test_scaled_log_reg_top3), y_test, pos_label = 'win'), 4), \n",
    "                               round(recall_score(log_reg_top3.predict(X_test_scaled_log_reg_top3), y_test, pos_label = 'loss'), 4), \n",
    "                               round(f1_score(log_reg_top3.predict(X_test_scaled_log_reg_top3), y_test, pos_label = 'win'), 4),\n",
    "                               round(f1_score(log_reg_top3.predict(X_test_scaled_log_reg_top3), y_test, pos_label = 'loss'), 4)])\n",
    "\n",
    "log_reg_evaluation = pd.DataFrame(log_reg_evaluation, evaluation_metrics).transpose()\n",
    "log_reg_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab04ef1d",
   "metadata": {},
   "source": [
    "## Model 2: Decision Tree\n",
    "\n",
    "The second model I will try is a Decision Tree. Again, I need to stick to classification models. Decision Trees are beneficial in that they are easier to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69927575",
   "metadata": {},
   "source": [
    "### Get top 3\n",
    "\n",
    "First I will build a model with all features, create an ordered list of the features by their importance, then I will extract the top 3. Those 3 features will be used to build the real model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af88a796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fg2_pct    0.154704\n",
       "fg3_pct    0.138294\n",
       "reb        0.133056\n",
       "ft_pct     0.077667\n",
       "fg3a       0.073994\n",
       "to         0.073337\n",
       "fta        0.072193\n",
       "stl        0.066246\n",
       "fg2a       0.066140\n",
       "pf         0.056075\n",
       "ast        0.047649\n",
       "blk        0.040645\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare a variable called entr_model and use tree.DecisionTreeClassifier. \n",
    "dec_tree = DecisionTreeClassifier(criterion = \"entropy\", random_state = 610)\n",
    "\n",
    "# Call fit() on entr_model\n",
    "dec_tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "dec_tree_feature_list = pd.Series(dec_tree.feature_importances_, index = dec_tree.feature_names_in_).sort_values(ascending = False) \n",
    "\n",
    "dec_tree_top_features = list(dec_tree_feature_list[0:3].index)\n",
    "dec_tree_feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b64346",
   "metadata": {},
   "source": [
    "The top 3 features are are, fg2a (2-pointers attempted), fg3a (3-pointers attempted), and reb (rebounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b88836",
   "metadata": {},
   "source": [
    "### Rebuild Model using Top 3 Features\n",
    "\n",
    "Now I will rebuild the model only using the top 3 feaures found in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "140f4c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_dec_tree_top3 = X_train_scaled[dec_tree_top_features]\n",
    "X_test_scaled_dec_tree_top3 = X_test_scaled[dec_tree_top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c0dd4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=610)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_top3 = DecisionTreeClassifier(criterion = \"entropy\", random_state = 610)\n",
    "dec_tree_top3.fit(X_train_scaled_dec_tree_top3, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a6c2d",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5890da4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Mean Score: 0.657 (Std: 0.0094)\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       0.66      0.65      0.65      7693\n",
      "         win       0.65      0.66      0.66      7706\n",
      "\n",
      "    accuracy                           0.65     15399\n",
      "   macro avg       0.65      0.65      0.65     15399\n",
      "weighted avg       0.65      0.65      0.65     15399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits = 10, random_state = 610, shuffle = True)\n",
    "scores = cross_val_score(dec_tree_top3, X_train_scaled_dec_tree_top3, y_train, cv = cv)\n",
    "print(\"Cross Validation Mean Score: \", round(np.mean(scores), 4), \" (Std: \", round(np.std(scores), 4), \")\", sep = \"\")\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, dec_tree_top3.predict(X_test_scaled_dec_tree_top3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0ab99be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features</th>\n",
       "      <th>train_cv_mean</th>\n",
       "      <th>train_cv_std</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_win</th>\n",
       "      <th>precision_loss</th>\n",
       "      <th>recall_win</th>\n",
       "      <th>recall_loss</th>\n",
       "      <th>f1_win</th>\n",
       "      <th>f1_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>[fg2_pct, fg3_pct, reb]</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.6595</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.6527</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.6519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model                    features       train_cv_mean  train_cv_std    \\\n",
       "0  Decision Tree  [fg2_pct, fg3_pct, reb]          0.657         0.0094   \n",
       "\n",
       "  accuracy       precision_win  precision_loss recall_win     recall_loss     \\\n",
       "0          0.654         0.6595         0.6485         0.6527         0.6553   \n",
       "\n",
       "  f1_win         f1_loss         \n",
       "0         0.6561         0.6519  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics = pd.array([\"model\", \"features\", \"train_cv_mean\", \"train_cv_std\", \"accuracy\", \"precision_win\", \"precision_loss\", \"recall_win\", \"recall_loss\", \"f1_win\", \"f1_loss\"])\n",
    "\n",
    "dec_tree_evaluation = pd.array([\"Decision Tree\", \n",
    "                                dec_tree_top_features,\n",
    "                                round(np.mean(scores), 4), \n",
    "                                round(np.std(scores), 4), \n",
    "                                round(accuracy_score(dec_tree_top3.predict(X_test_scaled_dec_tree_top3), y_test), 4), \n",
    "                                round(precision_score(dec_tree_top3.predict(X_test_scaled_dec_tree_top3), y_test, pos_label = 'win'), 4), \n",
    "                                round(precision_score(dec_tree_top3.predict(X_test_scaled_dec_tree_top3), y_test, pos_label = 'loss'), 4), \n",
    "                                round(recall_score(dec_tree_top3.predict(X_test_scaled_dec_tree_top3), y_test, pos_label = 'win'), 4), \n",
    "                                round(recall_score(dec_tree_top3.predict(X_test_scaled_dec_tree_top3), y_test, pos_label = 'loss'), 4), \n",
    "                                round(f1_score(dec_tree_top3.predict(X_test_scaled_dec_tree_top3), y_test, pos_label = 'win'), 4),\n",
    "                                round(f1_score(dec_tree_top3.predict(X_test_scaled_dec_tree_top3), y_test, pos_label = 'loss'), 4)])\n",
    "\n",
    "dec_tree_evaluation = pd.DataFrame(dec_tree_evaluation, evaluation_metrics).transpose()\n",
    "dec_tree_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d0ec2",
   "metadata": {},
   "source": [
    "## Model 3: Random Forest\n",
    "\n",
    "The last model I will try is the Random Forest. This is more powerful than a single Decision Tree, however it loses out on interpretability. Fortunately in this scenario, the details of how the model works aren’t very relevant and what matters is reducing the model to a few key inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3c02a8",
   "metadata": {},
   "source": [
    "### Get top 3\n",
    "\n",
    "First I will build a model with all features, create an ordered list of the features by their importance, then I will extract the top 3. Those 3 features will be used to build the real model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5434d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fg2_pct    0.152483\n",
       "fg3_pct    0.145871\n",
       "reb        0.126755\n",
       "ast        0.077766\n",
       "fta        0.071842\n",
       "fg3a       0.070037\n",
       "ft_pct     0.069851\n",
       "to         0.063353\n",
       "fg2a       0.058817\n",
       "pf         0.058231\n",
       "stl        0.057918\n",
       "blk        0.047075\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_for = RandomForestClassifier(n_estimators = 300, random_state = 1, n_jobs = -1)\n",
    "rand_for.fit(X_train_scaled, y_train)\n",
    "\n",
    "rand_for_feature_list = pd.Series(rand_for.feature_importances_, index = rand_for.feature_names_in_).sort_values(ascending = False) \n",
    "\n",
    "rand_for_top_features = list(rand_for_feature_list[0:3].index)\n",
    "rand_for_feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ee2b35",
   "metadata": {},
   "source": [
    "The top 3 features are are, fg2a (2-pointers attempted), fg3a (3-pointers attempted), and reb (rebounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e18eab",
   "metadata": {},
   "source": [
    "### Rebuild Model using Top 3 Features\n",
    "\n",
    "Now I will rebuild the model only using the top 3 feaures found in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3278636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_rand_for_top3 = X_train_scaled[rand_for_top_features]\n",
    "X_test_scaled_rand_for_top3 = X_test_scaled[rand_for_top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "213d0f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_for_top3 = RandomForestClassifier(n_estimators = 300, random_state = 1, n_jobs = -1)\n",
    "rand_for_top3.fit(X_train_scaled_rand_for_top3, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc70996b",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d386637b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Mean Score: 0.7043 (Std: 0.0082)\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       0.71      0.70      0.70      7693\n",
      "         win       0.70      0.71      0.71      7706\n",
      "\n",
      "    accuracy                           0.71     15399\n",
      "   macro avg       0.71      0.71      0.71     15399\n",
      "weighted avg       0.71      0.71      0.71     15399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits = 10, random_state = 610, shuffle = True)\n",
    "scores = cross_val_score(rand_for_top3, X_train_scaled_rand_for_top3, y_train, cv = cv)\n",
    "print(\"Cross Validation Mean Score: \", round(np.mean(scores), 4), \" (Std: \", round(np.std(scores), 4), \")\", sep = \"\")\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, rand_for_top3.predict(X_test_scaled_rand_for_top3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d964856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features</th>\n",
       "      <th>train_cv_mean</th>\n",
       "      <th>train_cv_std</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_win</th>\n",
       "      <th>precision_loss</th>\n",
       "      <th>recall_win</th>\n",
       "      <th>recall_loss</th>\n",
       "      <th>f1_win</th>\n",
       "      <th>f1_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>[fg2_pct, fg3_pct, reb]</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.7123</td>\n",
       "      <td>0.7004</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>0.7085</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.7044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model                    features       train_cv_mean  train_cv_std    \\\n",
       "0  Random Forest  [fg2_pct, fg3_pct, reb]         0.7043         0.0082   \n",
       "\n",
       "  accuracy       precision_win  precision_loss recall_win     recall_loss     \\\n",
       "0         0.7063         0.7123         0.7004         0.7043         0.7085   \n",
       "\n",
       "  f1_win         f1_loss         \n",
       "0         0.7083         0.7044  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics = pd.array([\"model\", \"features\", \"train_cv_mean\", \"train_cv_std\", \"accuracy\", \"precision_win\", \"precision_loss\", \"recall_win\", \"recall_loss\", \"f1_win\", \"f1_loss\"])\n",
    "\n",
    "rand_for_evaluation = pd.array([\"Random Forest\", \n",
    "                                rand_for_top_features, \n",
    "                                round(np.mean(scores), 4), \n",
    "                                round(np.std(scores), 4), \n",
    "                                round(accuracy_score(rand_for_top3.predict(X_test_scaled_rand_for_top3), y_test), 4), \n",
    "                                round(precision_score(rand_for_top3.predict(X_test_scaled_rand_for_top3), y_test, pos_label = 'win'), 4), \n",
    "                                round(precision_score(rand_for_top3.predict(X_test_scaled_rand_for_top3), y_test, pos_label = 'loss'), 4), \n",
    "                                round(recall_score(rand_for_top3.predict(X_test_scaled_rand_for_top3), y_test, pos_label = 'win'), 4), \n",
    "                                round(recall_score(rand_for_top3.predict(X_test_scaled_rand_for_top3), y_test, pos_label = 'loss'), 4), \n",
    "                                round(f1_score(rand_for_top3.predict(X_test_scaled_rand_for_top3), y_test, pos_label = 'win'), 4),\n",
    "                                round(f1_score(rand_for_top3.predict(X_test_scaled_rand_for_top3), y_test, pos_label = 'loss'), 4)])\n",
    "\n",
    "rand_for_evaluation = pd.DataFrame(rand_for_evaluation, evaluation_metrics).transpose()\n",
    "rand_for_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f49dff2",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31052bb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>train_cv_mean</th>\n",
       "      <th>train_cv_std</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_win</th>\n",
       "      <th>precision_loss</th>\n",
       "      <th>recall_win</th>\n",
       "      <th>recall_loss</th>\n",
       "      <th>f1_win</th>\n",
       "      <th>f1_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>[fg2_pct, fg3_pct, reb]</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.7123</td>\n",
       "      <td>0.7004</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>0.7085</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.7044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>[fg2_pct, fg3_pct, reb]</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.6595</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.6527</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.6519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>[reb, fg3a, fg2a]</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.6328</td>\n",
       "      <td>0.6287</td>\n",
       "      <td>0.6368</td>\n",
       "      <td>0.6342</td>\n",
       "      <td>0.6313</td>\n",
       "      <td>0.6315</td>\n",
       "      <td>0.6341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              features       train_cv_mean  train_cv_std    \\\n",
       "model                                                                        \n",
       "Random Forest        [fg2_pct, fg3_pct, reb]         0.7043         0.0082   \n",
       "Decision Tree        [fg2_pct, fg3_pct, reb]          0.657         0.0094   \n",
       "Logistic Regression        [reb, fg3a, fg2a]         0.6329         0.0068   \n",
       "\n",
       "                    accuracy       precision_win  precision_loss  \\\n",
       "model                                                              \n",
       "Random Forest               0.7063         0.7123         0.7004   \n",
       "Decision Tree                0.654         0.6595         0.6485   \n",
       "Logistic Regression         0.6328         0.6287         0.6368   \n",
       "\n",
       "                    recall_win     recall_loss    f1_win          \\\n",
       "model                                                              \n",
       "Random Forest               0.7043         0.7085         0.7083   \n",
       "Decision Tree               0.6527         0.6553         0.6561   \n",
       "Logistic Regression         0.6342         0.6313         0.6315   \n",
       "\n",
       "                    f1_loss         \n",
       "model                               \n",
       "Random Forest               0.7044  \n",
       "Decision Tree               0.6519  \n",
       "Logistic Regression         0.6341  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df = pd.concat([log_reg_evaluation, dec_tree_evaluation, rand_for_evaluation]).\\\n",
    "                set_index(\"model\").\\\n",
    "                sort_values(\"accuracy\", ascending = False)\n",
    "\n",
    "evaluation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8f9252",
   "metadata": {},
   "source": [
    "* Random Forest had the best performance in every test evaluation metric by a sizable margin making the choice an easy one. \n",
    "* The simpler Decision Tree also beat out Logistic Regression. \n",
    "* Both Random Forest and Decision Tree had the same top 3 features (fg2_pct, fg3_pct, reb) in that order.\n",
    "* This isn't present in the data but running Cross Validation using Random Forest took noticably longer than the other two models and caused the fans of my PC to start running pretty loud. This isn't an issue given the size and complexity of my model, but this would be a factor when done on a larger scale\n",
    "\n",
    "Interpretibilty isn't an issue for my hypothetical scenario because at the end of the day, teams just want to know what basketball stats to focus on. They don't care about the details of how the model works. Just that it's accurate. In conclusion, I'm going with Random Forest. Top 3 features are **2-point percent**, **3-point percent**, and **rebounds**. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
